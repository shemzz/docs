---
title: "Custom Evaluation"
description: "Create custom evaluation workflows tailored to your specific needs"
---

## **Overview**

Custom evaluations allow you to define specific criteria and metrics to assess your agent's performance beyond standard tests. This enables you to measure success according to your business requirements.

![Custom Evaluation Overview](/images/custom-evaluation-overview-placeholder.png)

## **What is Custom Evaluation?**

Custom evaluation lets you:
- Define your own success criteria
- Measure business-specific metrics
- Test compliance requirements
- Validate quality standards
- Track custom KPIs

## **Creating a Custom Evaluation**

### **Step 1: Define Evaluation Criteria**

Identify what to measure:
- **Accuracy**: Correctness of responses
- **Compliance**: Adherence to regulations
- **Quality**: Overall conversation quality
- **Business Metrics**: Custom business goals

![Evaluation Criteria](/images/evaluation-criteria-placeholder.png)

### **Step 2: Set Up Evaluation Rules**

Configure evaluation rules:
- **Scoring System**: How to score performance
- **Thresholds**: Minimum acceptable scores
- **Weighting**: Importance of different criteria
- **Validation**: How to validate results

### **Step 3: Create Test Cases**

Define test scenarios:
- **Test Cases**: Specific scenarios to test
- **Expected Outcomes**: What should happen
- **Success Criteria**: How to measure success
- **Data Requirements**: What data is needed

## **Evaluation Types**

### **1. Accuracy Evaluation**

Measure response correctness:
- **Factual Accuracy**: Are facts correct?
- **Context Accuracy**: Is context understood?
- **Intent Accuracy**: Is intent correctly identified?

### **2. Compliance Evaluation**

Test regulatory compliance:
- **GDPR Compliance**: Data privacy requirements
- **HIPAA Compliance**: Healthcare regulations
- **Industry Standards**: Sector-specific rules

### **3. Quality Evaluation**

Assess conversation quality:
- **Tone**: Appropriate tone and style
- **Clarity**: Clear communication
- **Helpfulness**: Useful responses
- **Professionalism**: Professional conduct

### **4. Business Metrics**

Measure business outcomes:
- **Conversion Rate**: Sales conversions
- **Satisfaction**: Customer satisfaction
- **Efficiency**: Time to resolution
- **Cost Savings**: Operational savings

## **Setting Up Evaluation Workflows**

### **Workflow Steps**

1. **Data Collection**: Gather test data
2. **Execution**: Run evaluations
3. **Analysis**: Analyze results
4. **Reporting**: Generate reports
5. **Action**: Take corrective action

![Evaluation Workflow](/images/evaluation-workflow-placeholder.png)

### **Automated Workflows**

Set up automated evaluation:
- **Scheduled Runs**: Regular evaluations
- **Triggered Runs**: Event-based evaluations
- **Continuous Monitoring**: Ongoing assessment
- **Alert System**: Notifications for issues

## **Best Practices**

### **1. Define Clear Criteria**

Make criteria specific and measurable:
- ✅ "Agent must provide accurate order status 95% of the time"
- ❌ "Agent should be helpful"

### **2. Use Real Data**

Test with actual scenarios:
- Real customer interactions
- Actual use cases
- Real-world data
- Production-like scenarios

### **3. Regular Evaluation**

Evaluate frequently:
- Before deployment
- After changes
- Regular intervals
- After incidents

### **4. Document Results**

Keep detailed records:
- Evaluation results
- Issues identified
- Improvements made
- Trends over time

### **5. Iterate and Improve**

Continuously refine:
- Update criteria
- Improve tests
- Refine metrics
- Optimize workflows

## **Troubleshooting**

<AccordionGroup>
  <Accordion title="Evaluation results are inconsistent">
    - Review evaluation criteria
    - Check test data quality
    - Verify evaluation rules
    - Standardize test scenarios
  </Accordion>

  <Accordion title="How do I create meaningful metrics?">
    - Align with business goals
    - Use industry standards
    - Consult with stakeholders
    - Start simple and expand
  </Accordion>

  <Accordion title="Evaluations take too long">
    - Optimize test cases
    - Reduce test data
    - Parallelize execution
    - Use sampling
  </Accordion>
</AccordionGroup>

## **Next Steps**

<CardGroup cols={2}>
  <Card title="Simulations" icon="flask" href="/evaluate/simulations">
    Test with realistic scenarios
  </Card>
  <Card title="Manual Testing" icon="bug" href="/evaluate/test-your-agent">
    Test your agent manually
  </Card>
  <Card title="Analytics" icon="chart-line" href="/learn/analytics-dashboard">
    Monitor production metrics
  </Card>
</CardGroup>

